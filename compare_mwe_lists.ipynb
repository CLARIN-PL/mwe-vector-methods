{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e76bda-e962-404c-906b-0900f40d256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import string\n",
    "\n",
    "import morfeusz2\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b851c6-3867-4d01-9091-57dcd0faeb88",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Load MWE lists</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67779958-0edb-44f0-b53a-4983206aff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "parseme_correct_mwe_filepath = os.path.join('PARSEME_1.2_Polish_Dataset', 'PL', 'train_df.tsv')\n",
    "parseme_incorrect_mwe_filepath = 'parseme_incorrect_mwes.tsv'\n",
    "\n",
    "kgr10_correct_mwe_filepath = 'correct_mwe.tsv'\n",
    "kgr10_incorrect_mwe_filepath = 'incorrect_MWE_kompozycyjne_polaczenia_plWN.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713e4264-4b63-4aad-bdeb-7aec8026540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSEME correct MWE: 3859\n",
      "PARSEME incorrect MWE: 29027\n",
      "KGR10 correct MWE: 53978\n",
      "KGR10 incorrect MWE: 5249\n"
     ]
    }
   ],
   "source": [
    "parseme_train_correct_df = pd.read_csv(parseme_correct_mwe_filepath, sep='\\t')\n",
    "parseme_train_correct_df = parseme_train_correct_df[parseme_train_correct_df['parseme:mwe'] != '*']\n",
    "parseme_train_correct_mwe_list = []\n",
    "parseme_train_correct_mwe_list_lemmatized = []\n",
    "\n",
    "first_word_id = 0\n",
    "curr_word_id = 0\n",
    "curr_sent_id = 0\n",
    "mwe_words_list = []\n",
    "mwe_lemmas_list = []\n",
    "\n",
    "for ind, row in parseme_train_correct_df.iterrows():\n",
    "    if len(row['parseme:mwe']) > 1:\n",
    "        if len(mwe_words_list) > 1:\n",
    "            parseme_train_correct_mwe_list.append(' '.join(mwe_words_list))\n",
    "            parseme_train_correct_mwe_list_lemmatized.append(' '.join(mwe_lemmas_list))\n",
    "        \n",
    "        first_word_id = int(row['id'])\n",
    "        curr_word_id = int(row['id'])\n",
    "        curr_sent_id = int(row['sent_id'])\n",
    "\n",
    "        mwe_words_list = [row['form']]\n",
    "        mwe_lemmas_list = [row['lemma']]\n",
    "        \n",
    "    if len(row['parseme:mwe']) == 1:\n",
    "        if int(row['sent_id']) == curr_sent_id and int(row['id']) == curr_word_id + 1:\n",
    "            curr_word_id = int(row['id'])\n",
    "            curr_sent_id = int(row['sent_id'])\n",
    "        \n",
    "            mwe_words_list.append(row['form'])\n",
    "            mwe_lemmas_list.append(row['lemma'])\n",
    "\n",
    "parseme_train_incorrect_mwe_df = pd.read_csv(parseme_incorrect_mwe_filepath, sep='\\t')\n",
    "parseme_train_incorrect_mwe_list = [' '.join([str(first_word).lower(), str(second_word).lower()]) for first_word, second_word in zip(parseme_train_incorrect_mwe_df['first_word'].tolist(), parseme_train_incorrect_mwe_df['second_word'].tolist())]\n",
    "\n",
    "kgr10_correct_mwe_df = pd.read_csv(kgr10_correct_mwe_filepath, sep='\\t')\n",
    "kgr10_correct_mwe_list = [mwe.lower() for mwe in kgr10_correct_mwe_df['Lemma'].tolist()]\n",
    "\n",
    "kgr10_incorrect_mwe_df = pd.read_csv(kgr10_incorrect_mwe_filepath, sep=',', on_bad_lines='skip')\n",
    "kgr10_incorrect_mwe_list = [mwe.lower() for mwe in kgr10_incorrect_mwe_df['lemma'].tolist()]\n",
    "\n",
    "print(f'PARSEME correct MWE: {len(parseme_train_correct_mwe_list)}',\n",
    "      f'PARSEME incorrect MWE: {len(parseme_train_incorrect_mwe_list)}',\n",
    "      f'KGR10 correct MWE: {len(kgr10_correct_mwe_list)}',\n",
    "      f'KGR10 incorrect MWE: {len(kgr10_incorrect_mwe_list)}',\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa700c25-d3ef-4ce4-8e15-12a686bac2f2",
   "metadata": {},
   "source": [
    "<h4>Compare MWE lists</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2228ff-6e3a-4878-b08d-fb11377ce20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGR10 correct intersection PARSEME correct: 127\n",
      "KGR10 correct intersection PARSEME incorrect: 408\n",
      "KGR10 incorrect intersection PARSEME correct: 5\n",
      "KGR10 incorrect intersection PARSEME incorrect: 41\n",
      "2608\n"
     ]
    }
   ],
   "source": [
    "# compare without lemmatization\n",
    "kgr10_corr_parseme_corr_intersect = set(kgr10_correct_mwe_list).intersection(set(parseme_train_correct_mwe_list))\n",
    "kgr10_corr_parseme_incorr_intersect = set(kgr10_correct_mwe_list).intersection(set(parseme_train_incorrect_mwe_list))\n",
    "\n",
    "kgr10_incorr_parseme_corr_intersect = set(kgr10_incorrect_mwe_list).intersection(set(parseme_train_correct_mwe_list))\n",
    "kgr10_incorr_parseme_incorr_intersect = set(kgr10_incorrect_mwe_list).intersection(set(parseme_train_incorrect_mwe_list))\n",
    "\n",
    "print(f'KGR10 correct intersection PARSEME correct: {len(kgr10_corr_parseme_corr_intersect)}',\n",
    "      f'KGR10 correct intersection PARSEME incorrect: {len(kgr10_corr_parseme_incorr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME correct: {len(kgr10_incorr_parseme_corr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME incorrect: {len(kgr10_incorr_parseme_incorr_intersect)}',\n",
    "      sep='\\n')\n",
    "print(len(set(parseme_train_correct_mwe_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebed727-a9c1-4a24-866c-cf92d27a1c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGR10 correct intersection PARSEME correct: 138\n",
      "KGR10 correct intersection PARSEME incorrect: 778\n",
      "KGR10 incorrect intersection PARSEME correct: 16\n",
      "KGR10 incorrect intersection PARSEME incorrect: 153\n"
     ]
    }
   ],
   "source": [
    "# compare without lemmatization with checking if MWE is a part of MWE in another list\n",
    "# kgr10_corr_parseme_corr_intersect = set(kgr10_correct_mwe_list).intersection(set(parseme_train_correct_mwe_list))\n",
    "kgr10_corr_parseme_corr_intersect = [parseme_mwe for parseme_mwe in set(parseme_train_correct_mwe_list) if parseme_mwe in set(kgr10_correct_mwe_list) or any(parseme_mwe in kgr10_mwe for kgr10_mwe in kgr10_correct_mwe_list)]\n",
    "# kgr10_corr_parseme_incorr_intersect = set(kgr10_correct_mwe_list).intersection(set(parseme_train_incorrect_mwe_list))\n",
    "kgr10_corr_parseme_incorr_intersect = [parseme_mwe for parseme_mwe in set(parseme_train_incorrect_mwe_list) if parseme_mwe in set(kgr10_correct_mwe_list) or any(parseme_mwe in kgr10_mwe for kgr10_mwe in kgr10_correct_mwe_list)]\n",
    "\n",
    "# kgr10_incorr_parseme_corr_intersect = set(kgr10_incorrect_mwe_list).intersection(set(parseme_train_correct_mwe_list))\n",
    "kgr10_incorr_parseme_corr_intersect = [parseme_mwe for parseme_mwe in set(parseme_train_correct_mwe_list) if parseme_mwe in set(kgr10_incorrect_mwe_list) or any(parseme_mwe in kgr10_mwe for kgr10_mwe in kgr10_incorrect_mwe_list)]\n",
    "# kgr10_incorr_parseme_incorr_intersect = set(kgr10_incorrect_mwe_list).intersection(set(parseme_train_incorrect_mwe_list))\n",
    "kgr10_incorr_parseme_incorr_intersect = [parseme_mwe for parseme_mwe in set(parseme_train_incorrect_mwe_list) if parseme_mwe in set(kgr10_incorrect_mwe_list) or any(parseme_mwe in kgr10_mwe for kgr10_mwe in kgr10_incorrect_mwe_list)]\n",
    "\n",
    "print(f'KGR10 correct intersection PARSEME correct: {len(kgr10_corr_parseme_corr_intersect)}',\n",
    "      f'KGR10 correct intersection PARSEME incorrect: {len(kgr10_corr_parseme_incorr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME correct: {len(kgr10_incorr_parseme_corr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME incorrect: {len(kgr10_incorr_parseme_incorr_intersect)}',\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0bdefba-034b-45b5-a729-687cef1b2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lists to CSV\n",
    "filenames = ['kgr10_corr_parseme_corr_intersect.csv', 'kgr10_corr_parseme_incorr_intersect.csv', 'kgr10_incorr_parseme_corr_intersect.csv', 'kgr10_incorr_parseme_incorr_intersect.csv']\n",
    "mwe_lists = [kgr10_corr_parseme_corr_intersect, kgr10_corr_parseme_incorr_intersect, kgr10_incorr_parseme_corr_intersect, kgr10_incorr_parseme_incorr_intersect]\n",
    "\n",
    "for ind, mwe_list in enumerate(mwe_lists):\n",
    "    with open(filenames[ind], 'w', encoding='utf-8') as out_file:\n",
    "        out_file.write('\\n'.join(mwe_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f6610-b385-4b4f-bbed-25b4504abad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many MWE longer than 2 words are in the datasets\n",
    "for dataset in [set(kgr10_correct_mwe_list), set(kgr10_incorrect_mwe_list), set(parseme_train_correct_mwe_list), set(parseme_train_incorrect_mwe_list)]:\n",
    "    longer_mwe_count = 0\n",
    "    for mwe in dataset:\n",
    "        if len(mwe.split(' ')) > 2:\n",
    "            longer_mwe_count += 1\n",
    "            \n",
    "    print(f'MWE longer than 2 words: {longer_mwe_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10f9565-8330-4ed9-9c54-e8cd748039e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Morfeusz2 lemmatizer\n",
    "def init_lemmatizer():\n",
    "    return morfeusz2.Morfeusz()  # initialize Morfeusz object\n",
    "\n",
    "\n",
    "# lemmatize MWEs\n",
    "def lemmatize_mwe(mwe_list, lemmatizer) -> List[str]:\n",
    "    lemmatized_mwe_list = ['*' * 200 for _ in range(len(mwe_list))]\n",
    "\n",
    "    for i, mwe in enumerate(mwe_list):\n",
    "        mwe_words = [token for token in mwe.split(' ')]\n",
    "        lemmatized_mwe_list[i] = ' '.join(\n",
    "            [str(lemmatizer.analyse(word)[0][2][1]) if word not in string.punctuation else word for word in mwe_words])\n",
    "\n",
    "    return lemmatized_mwe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55bca47-cf98-4f1c-8cda-3568dd6329a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGR10 correct intersection PARSEME correct: 439\n",
      "KGR10 correct intersection PARSEME incorrect: 1238\n",
      "KGR10 incorrect intersection PARSEME correct: 31\n",
      "KGR10 incorrect intersection PARSEME incorrect: 137\n"
     ]
    }
   ],
   "source": [
    "# compare with lemmatization\n",
    "lemmatizer = init_lemmatizer()\n",
    "\n",
    "parseme_train_incorrect_mwe_list_lemmatized = lemmatize_mwe(parseme_train_incorrect_mwe_list, lemmatizer)\n",
    "kgr10_correct_mwe_list_lemmatized = lemmatize_mwe(kgr10_correct_mwe_list, lemmatizer)\n",
    "kgr10_incorrect_mwe_list_lemmatized = lemmatize_mwe(kgr10_incorrect_mwe_list, lemmatizer)\n",
    "\n",
    "kgr10_corr_parseme_corr_intersect = set(kgr10_correct_mwe_list_lemmatized).intersection(set(parseme_train_correct_mwe_list_lemmatized))\n",
    "kgr10_corr_parseme_incorr_intersect = set(kgr10_correct_mwe_list_lemmatized).intersection(set(parseme_train_incorrect_mwe_list_lemmatized))\n",
    "\n",
    "kgr10_incorr_parseme_corr_intersect = set(kgr10_incorrect_mwe_list_lemmatized).intersection(set(parseme_train_correct_mwe_list_lemmatized))\n",
    "kgr10_incorr_parseme_incorr_intersect = set(kgr10_incorrect_mwe_list_lemmatized).intersection(set(parseme_train_incorrect_mwe_list_lemmatized))\n",
    "\n",
    "print(f'KGR10 correct intersection PARSEME correct: {len(kgr10_corr_parseme_corr_intersect)}',\n",
    "      f'KGR10 correct intersection PARSEME incorrect: {len(kgr10_corr_parseme_incorr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME correct: {len(kgr10_incorr_parseme_corr_intersect)}',\n",
    "      f'KGR10 incorrect intersection PARSEME incorrect: {len(kgr10_incorr_parseme_incorr_intersect)}',\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec933fbe-c02d-4ff8-8131-406c2dd6e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of correct MWE: 2331\n",
      "No. of incorrect MWE: 25648\n",
      "No. of total MWE: 27979\n",
      "MWE lemma intersection: 0\n",
      "No. of sentences in corr dataset with shared MWE: 0\n",
      "No. of sentences in incorr dataset with shared MWE: 0\n",
      "No. of sentences in total: 32407\n",
      "No. of sentences with zdecydować się in corr: 26\n",
      "No. of sentences with zdecydować się in incorr: 0\n"
     ]
    }
   ],
   "source": [
    "# compare MWE lists of PARSEME and get number of sentences with MWEs shared between correct and incorrect MWEs\n",
    "df_corr = pd.read_csv('parseme_correct_mwes.tsv', sep='\\t')\n",
    "df_incorr = pd.read_csv('parseme_incorrect_mwes.tsv', sep='\\t')\n",
    "mwe_lemma_intersection = set(df_corr['full_mwe_lemma'].tolist()).intersection(set(df_incorr['full_mwe_lemma']))\n",
    "\n",
    "print(f\"No. of correct MWE: {len(df_corr['full_mwe'].unique().tolist())}\",\n",
    "      f\"No. of incorrect MWE: {len(df_incorr['full_mwe'].unique().tolist())}\",\n",
    "      f\"No. of total MWE: {len(df_corr['full_mwe'].unique().tolist()) + len(df_incorr['full_mwe'].unique().tolist())}\",\n",
    "      sep='\\n')\n",
    "\n",
    "print(f'MWE lemma intersection: {len(mwe_lemma_intersection)}',\n",
    "      f'No. of sentences in corr dataset with shared MWE: {len(df_corr[df_corr[\"full_mwe_lemma\"].isin(list(mwe_lemma_intersection))])}',\n",
    "      f'No. of sentences in incorr dataset with shared MWE: {len(df_incorr[df_incorr[\"full_mwe_lemma\"].isin(list(mwe_lemma_intersection))])}',\n",
    "      f'No. of sentences in total: {len(df_corr) + len(df_incorr)}',\n",
    "      sep='\\n')\n",
    "\n",
    "print(f'No. of sentences with zdecydować się in corr: {len(df_corr[df_corr[\"full_mwe_lemma\"] == \"zdecydować się\"])}',\n",
    "      f'No. of sentences with zdecydować się in incorr: {len(df_incorr[df_incorr[\"full_mwe_lemma\"] == \"zdecydować się\"])}',\n",
    "      sep='\\n')\n",
    "\n",
    "# df_corr[df_corr[\"full_mwe_lemma\"] == \"nie mieć\"].to_csv('parseme_sentences_with_nie_miec.tsv', sep='\\t', index=False)\n",
    "\n",
    "df_intersection = df_corr[df_corr[\"full_mwe_lemma\"].isin(list(mwe_lemma_intersection))].append(df_incorr[df_incorr[\"full_mwe_lemma\"].isin(list(mwe_lemma_intersection))])\n",
    "df_intersection.to_csv('parseme_correct_incorrect_intersection.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a71d3a6-4765-427a-afef-0d79b9d2570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct MWE occurrences, where they are not tagged as correct\n",
    "correct_mwe_lemma_list = pd.read_csv('parseme_correct_mwes.tsv', sep='\\t')['full_mwe_lemma'].tolist()\n",
    "df_train = pd.read_csv('PARSEME_1.2_Polish_Dataset/PL/train_df.tsv', sep='\\t')\n",
    "\n",
    "correct_pos = ['VERB+PRON', 'VERB+NOUN', 'ADJ+NOUN', 'VERB+ADP', 'ADJ+PRON', \n",
    "               'NOUN+VERB', 'NOUN+NOUN', 'NOUN+ADJ', 'ADP+NOUN', 'NOUN+PRON']\n",
    "\n",
    "mwe_count = 0\n",
    "mwe_count_dict = {}\n",
    "final_df = pd.DataFrame(columns=['type', 'first_word', 'first_word_lemma', 'first_word_id',\n",
    "                                      'second_word', 'second_word_lemma', 'second_word_id',\n",
    "                                      'full_mwe', 'full_mwe_lemma', 'sentence'])\n",
    "longer_mwe_list = []\n",
    "for sent_id in df_train['sent_id'].unique().tolist():\n",
    "    pos_list = df_train[df_train['sent_id'] == sent_id]['upos'].tolist()\n",
    "    idx_list = df_train[df_train['sent_id'] == sent_id]['id'].tolist()\n",
    "    form_list = df_train[df_train['sent_id'] == sent_id]['form'].tolist()\n",
    "    lemma_list = df_train[df_train['sent_id'] == sent_id]['lemma'].tolist()\n",
    "    mwe_tag_list = df_train[df_train['sent_id'] == sent_id]['parseme:mwe'].tolist()\n",
    "    deprel_list = df_train[df_train['sent_id'] == sent_id]['deprel'].tolist()\n",
    "    deps_list = [ast.literal_eval(elem) if type(elem) == str else [] for elem in df_train[df_train['sent_id'] == sent_id]['deps'].tolist()]\n",
    "    sentence = ' '.join([str(word) for word in form_list])\n",
    "        \n",
    "    mwe_part_ind = [False for _ in range(len(lemma_list))]\n",
    "    mwe = ''\n",
    "    mwe_pos = ''\n",
    "    for ind, mwe_tag in enumerate(mwe_tag_list[:-1]):\n",
    "        if mwe_tag == '*':\n",
    "            if mwe != '' and len(mwe.split(' ')) > 2:\n",
    "                longer_mwe_list.append((mwe, sentence))\n",
    "            mwe = ''\n",
    "            mwe_pos = ''\n",
    "            \n",
    "        else:\n",
    "            if mwe == '':\n",
    "                mwe = form_list[ind]\n",
    "                mwe_pos = pos_list[ind]\n",
    "            else:\n",
    "                mwe_pos += f'+{pos_list[ind]}'\n",
    "                mwe += f' {form_list[ind]}'\n",
    "                \n",
    "with open('parseme_mwes_longer_than_2.tsv', 'w') as out_file:\n",
    "    for mwe_tuple in longer_mwe_list:\n",
    "        out_file.write(f'{mwe_tuple[0]}\\t{mwe_tuple[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b26583-a2c4-4930-9043-fe599cd86c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Takie', '*'], ['są', '*'], ['najświeższe', '*'], ['wyniki', '*'], ['ankiety', '1:LVC.full'], ['przeprowadzonej', '1'], ['wśród', '*'], ['bankowców', '*'], ['przez', '*'], ['Pentor', '*'], ['na', '*'], ['zlecenie', '*'], ['Związku', '*'], ['Banków', '*'], ['Polskich', '*'], ['.', '*']]\n"
     ]
    }
   ],
   "source": [
    "# search for piece of sentence across all sentence that may contain it in the train set\n",
    "\n",
    "for sent_id in df_train['sent_id'].unique().tolist():\n",
    "    pos_list = df_train[df_train['sent_id'] == sent_id]['upos'].tolist()\n",
    "    idx_list = df_train[df_train['sent_id'] == sent_id]['id'].tolist()\n",
    "    form_list = df_train[df_train['sent_id'] == sent_id]['form'].tolist()\n",
    "    lemma_list = df_train[df_train['sent_id'] == sent_id]['lemma'].tolist()\n",
    "    mwe_tag_list = df_train[df_train['sent_id'] == sent_id]['parseme:mwe'].tolist()\n",
    "    deprel_list = df_train[df_train['sent_id'] == sent_id]['deprel'].tolist()\n",
    "    deps_list = [ast.literal_eval(elem) if type(elem) == str else [] for elem in df_train[df_train['sent_id'] == sent_id]['deps'].tolist()]\n",
    "    sentence = ' '.join([str(word) for word in form_list])\n",
    "    if 'ankiety przeprowadzonej' in sentence:\n",
    "        print(f'{[[word, mwe_tag] for word, mwe_tag in zip(form_list, mwe_tag_list)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf775f07-e635-4ded-b166-0e96a34543de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentences containing untagged correct MWEs: 183\n",
      "No. of unique MWEs: 131\n"
     ]
    }
   ],
   "source": [
    "# count sentences containing untagged correct MWEs\n",
    "df_train = pd.read_csv('PARSEME_1.2_Polish_Dataset/PL/train_df.tsv', sep='\\t')\n",
    "\n",
    "correct_mwe_lemma_list = pd.read_csv('parseme_correct_mwes.tsv', sep='\\t')['full_mwe_lemma'].tolist()\n",
    "\n",
    "untagged_corr_mwe_df = pd.DataFrame(columns=['type', 'first_word', 'first_word_lemma', 'first_word_id',\n",
    "                                             'second_word', 'second_word_lemma', 'second_word_id',\n",
    "                                             'full_mwe', 'full_mwe_lemma', 'sentence'])\n",
    "\n",
    "for sent_id in df_train['sent_id'].unique().tolist():\n",
    "    pos_list = df_train[df_train['sent_id'] == sent_id]['upos'].tolist()\n",
    "    idx_list = df_train[df_train['sent_id'] == sent_id]['id'].tolist()\n",
    "    form_list = df_train[df_train['sent_id'] == sent_id]['form'].tolist()\n",
    "    lemma_list = df_train[df_train['sent_id'] == sent_id]['lemma'].tolist()\n",
    "    mwe_tag_list = df_train[df_train['sent_id'] == sent_id]['parseme:mwe'].tolist()\n",
    "    deprel_list = df_train[df_train['sent_id'] == sent_id]['deprel'].tolist()\n",
    "    deps_list = [ast.literal_eval(elem) if type(elem) == str else [] for elem in df_train[df_train['sent_id'] == sent_id]['deps'].tolist()]\n",
    "    sentence = ' '.join([str(word) for word in form_list])\n",
    "    \n",
    "    for lemma_ind, lemma in enumerate(lemma_list[:-1]):\n",
    "        first_pos = pos_list[lemma_ind]\n",
    "        second_pos = pos_list[lemma_ind + 1]\n",
    "        mwe_pos = f'{first_pos}+{second_pos}'\n",
    "        \n",
    "        mwe_lemma = f'{str(lemma_list[lemma_ind])} {str(lemma_list[lemma_ind + 1])}'\n",
    "        \n",
    "        if (mwe_lemma in correct_mwe_lemma_list and \n",
    "            mwe_tag_list[lemma_ind] == '*' and \n",
    "            mwe_tag_list[lemma_ind + 1 ] == '*'):\n",
    "            # append MWE to DataFrame\n",
    "            untagged_corr_mwe_df = untagged_corr_mwe_df.append({'type': mwe_pos, \n",
    "                                                                'first_word': form_list[lemma_ind], \n",
    "                                                                'first_word_lemma': lemma_list[lemma_ind],\n",
    "                                                                'first_word_id': lemma_ind,\n",
    "                                                                'second_word': form_list[lemma_ind + 1],\n",
    "                                                                'second_word_lemma': lemma_list[lemma_ind + 1],\n",
    "                                                                'second_word_id': int(lemma_ind) + 1,\n",
    "                                                                'full_mwe': str(form_list[lemma_ind]) + ' ' + str(form_list[lemma_ind + 1]),\n",
    "                                                                'full_mwe_lemma': str(lemma_list[lemma_ind]) + ' ' + str(lemma_list[lemma_ind + 1]),\n",
    "                                                                'sentence': sentence}, \n",
    "                                                               ignore_index=True)\n",
    "        \n",
    "\n",
    "print(f'No. of sentences containing untagged correct MWEs: {len(untagged_corr_mwe_df)}',\n",
    "      f'No. of unique MWEs: {len(untagged_corr_mwe_df[\"full_mwe\"].unique().tolist())}',\n",
    "      sep='\\n')\n",
    "untagged_corr_mwe_df.to_csv('parseme_untagged_correct_mwe.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60890c9-3650-49e5-a318-7da8c88a3338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 298437\n",
      "Tokens tagged as correct: 11379\n"
     ]
    }
   ],
   "source": [
    "# count tokens related to correct MWEs and total number of tokens\n",
    "df_train = pd.read_csv('PARSEME_1.2_Polish_Dataset/PL/train_df.tsv', sep='\\t')\n",
    "print(f'Total tokens: {len(df_train)}',\n",
    "      f'Tokens tagged as correct: {len(df_train[df_train[\"parseme:mwe\"] != \"*\"])}',\n",
    "      sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
